{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global vars/imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir='/tmp/cars'\n",
    "model_dir=base_dir + '/model'\n",
    "dataset_dir='https://workshopml.spock.cloud/datasets/cars'\n",
    "pre_trained_model='https://workshopml.spock.cloud/models/cars/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel conda_mxnet_p36\n",
    "\n",
    "%matplotlib inline\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import sagemaker\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import inspect\n",
    "import random\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "from PIL import Image\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "print(mx.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MxNet container functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training method\n",
    "def train(current_host, hosts, num_cpus, num_gpus, channel_input_dirs, model_dir, hyperparameters, **kwargs):\n",
    "    \n",
    "    # Helper class for keeping track of accuracy\n",
    "    class EpochCheckpoint(object):\n",
    "        def __init__(self):\n",
    "            self.best_epoch_accuracy = 0.0\n",
    "            self.best_epoch_id = -1\n",
    "\n",
    "        def __call__(self, param): \n",
    "            if param.eval_metric is not None:\n",
    "                name_value = param.eval_metric.get_name_value()\n",
    "                epoch_accuracy = list(i[1] for i in name_value)[0]\n",
    "\n",
    "                if epoch_accuracy > self.best_epoch_accuracy:\n",
    "                    self.best_epoch_accuracy = epoch_accuracy\n",
    "                    self.best_epoch_id = param.epoch+1\n",
    "    \n",
    "    print(hyperparameters)\n",
    "    # retrieve the hyperparameters we set in notebook (with some defaults)\n",
    "    batch_size = hyperparameters.get('batch_size', 128)\n",
    "    epochs = hyperparameters.get('epochs', 100)\n",
    "    learning_rate = hyperparameters.get('learning_rate', 0.00007)\n",
    "    log_interval = hyperparameters.get('log_interval', 50)\n",
    "    data_dir = channel_input_dirs['training']\n",
    "\n",
    "    ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "    mx.random.seed(127)\n",
    "    num_classes=196\n",
    "\n",
    "    # Download a pre trained ImageNet 11k\n",
    "    path='http://data.mxnet.io/models/imagenet-11k/'\n",
    "    [mx.test_utils.download(path+'resnet-152/resnet-152-symbol.json', dirname=base_dir),\n",
    "     mx.test_utils.download(path+'resnet-152/resnet-152-0000.params', dirname=base_dir),\n",
    "     mx.test_utils.download(path+'synset.txt', dirname=base_dir)]   \n",
    "    \n",
    "    sym, arg_params, aux_params = mx.model.load_checkpoint(base_dir + '/resnet-152', 0)\n",
    "    mod = mx.mod.Module(symbol=sym, context=ctx, label_names=None)\n",
    "    mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "             label_shapes=mod._label_shapes)\n",
    "    mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "    \n",
    "    # slicing the trained resnet to create the Frankenstein\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers['flatten0_output']\n",
    "    net = mx.symbol.Dropout(data=net, p=0.7, name='drop1')\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.Dropout(data=net, p=0.2, name='drop1')\n",
    "    net = mx.symbol.SVMOutput(data=net, name='svm')\n",
    "    \n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})\n",
    "\n",
    "    new_args['fc1_weight'] = mx.nd.zeros((num_classes,2048))\n",
    "    new_args['fc1_bias'] = mx.nd.zeros((num_classes))\n",
    "\n",
    "    w = arg_params['fc1_weight']\n",
    "    b = arg_params['fc1_bias']\n",
    "    \n",
    "    # Load the new model\n",
    "    deep_car_mod = mx.mod.Module(symbol=net, context=ctx, label_names=[ 'svm_label'])\n",
    "    deep_car_mod.bind(for_training=True, data_shapes=[('data', (batch_size,3,224,224))], \n",
    "             label_shapes=[('svm_label', (batch_size,))])\n",
    "    deep_car_mod.init_params(mx.initializer.Xavier(rnd_type=\"uniform\", magnitude=\"2.34\"))\n",
    "    deep_car_mod.set_params(new_args, aux_params, allow_missing=False)\n",
    "    \n",
    "    train_data = get_train_data(data_dir, batch_size, (3, 224, 224))\n",
    "    test_data = get_test_data(data_dir, batch_size, (3, 224, 224))\n",
    "\n",
    "    model_filename_prefix = os.path.join(model_dir, 'cars_labels_model' )\n",
    "    epoch_checkpoint = EpochCheckpoint()\n",
    "    \n",
    "    # train with the same\n",
    "    deep_car_mod.fit(train_data,\n",
    "        eval_data=test_data,\n",
    "        optimizer='adam',\n",
    "        optimizer_params={'learning_rate':learning_rate},\n",
    "        eval_metric='acc',\n",
    "        epoch_end_callback=mx.callback.do_checkpoint(model_filename_prefix),\n",
    "        batch_end_callback=mx.callback.Speedometer(batch_size, log_interval),\n",
    "        eval_end_callback=epoch_checkpoint,\n",
    "        num_epoch=epochs,\n",
    "        force_init=True)\n",
    "\n",
    "    print(\"Best epoch id: %d - Accuracy: %f\" % (epoch_checkpoint.best_epoch_id, epoch_checkpoint.best_epoch_accuracy ) )\n",
    "    \n",
    "    os.rename(model_filename_prefix + '-%04d.params' % epoch_checkpoint.best_epoch_id,\n",
    "        model_filename_prefix + '-best.params' )\n",
    "\n",
    "    return deep_car_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the best accuracy model\n",
    "def save(net, model_dir):\n",
    "    # model_dir will be empty except on primary container\n",
    "    files = os.listdir(model_dir)\n",
    "    if files:\n",
    "        for i in files:\n",
    "            if i.endswith('params') and not i.endswith('best.params'):\n",
    "                os.remove( os.path.join(model_dir, i) )\n",
    "        os.rename( os.path.join(model_dir, 'cars_labels_model-best.params' ),\n",
    "            os.path.join(model_dir, 'cars_labels_model-0000.params' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the test data iterator\n",
    "def get_test_data(data_dir, batch_size, data_shape):\n",
    "    return mx.image.ImageIter(\n",
    "        batch_size=batch_size, \n",
    "        data_shape=data_shape,\n",
    "        path_imglist=os.path.join(data_dir, 'cars_test.lst'),\n",
    "        path_imgrec=os.path.join(data_dir, 'cars_test.rec') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the train data iterator\n",
    "def get_train_data(data_dir, batch_size, data_shape):\n",
    "    return mx.image.ImageIter(\n",
    "        batch_size=batch_size, \n",
    "        data_shape=data_shape,\n",
    "        path_imglist=os.path.join(data_dir, 'cars_train.lst'),\n",
    "        path_imgrec=os.path.join(data_dir, 'cars_train.rec') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation method\n",
    "def test(ctx, net, test_data):\n",
    "    test_data.reset()\n",
    "    metric = mx.metric.Accuracy()\n",
    "    \n",
    "    Batch = namedtuple('Batch', ['data'])\n",
    "    \n",
    "    outputs = []\n",
    "    for i, batch in enumerate(test_data):\n",
    "        label = batch.label\n",
    "        for img in batch.data:\n",
    "            net.forward(Batch([img]))\n",
    "            outputs.append(net.get_outputs())\n",
    "        metric.update(label, outputs)\n",
    "     \n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the saved model and return it\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the model. Called once when hosting service starts.\n",
    "\n",
    "    :param: model_dir The directory where model files are stored.\n",
    "    :return: a model (in this case a network)\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size=1\n",
    "    sym, arg_params, aux_params = mx.model.load_checkpoint(os.path.join(model_dir, 'cars_labels_model'), 0)\n",
    "    deep_car_mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=[ 'svm_label'])\n",
    "    deep_car_mod.bind(for_training=False, data_shapes=[('data', (batch_size,3,224,224))], label_shapes=deep_car_mod._label_shapes)\n",
    "    deep_car_mod.set_params(arg_params, aux_params, allow_missing=False)\n",
    "\n",
    "    return deep_car_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the prediction and return the top-5 classes\n",
    "def transform_fn(net, data, input_content_type, output_content_type):\n",
    "    \"\"\"\n",
    "    Transform a request using the model. Called once per request.\n",
    "\n",
    "    :param net: The model.\n",
    "    :param data: The request payload.\n",
    "    :param input_content_type: The request content type.\n",
    "    :param output_content_type: The (desired) response content type.\n",
    "    :return: response payload and content type.\n",
    "    \"\"\"\n",
    "    resp = []\n",
    "    try:\n",
    "        # we can use content types to vary input/output handling, but\n",
    "        # here we just assume json for both\n",
    "        Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "        parsed = json.loads(data)\n",
    "        img = mx.nd.array(parsed)\n",
    "\n",
    "        net.forward(Batch([mx.nd.array(img)]))\n",
    "        prob = net.get_outputs()[0][0].asnumpy()\n",
    "\n",
    "        # print the top-5\n",
    "        prob = np.squeeze(prob)\n",
    "        a = np.argsort(prob)[::-1]\n",
    "        resp = []\n",
    "        for i in a[0:5]:\n",
    "            resp.append({\"%d\"%i: float(prob[i])})\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "\n",
    "    return json.dumps(resp), output_content_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder for converting numpy to json\n",
    "class NumPyArangeEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist() # or map(int, obj)\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(val_iter, endpoint_name=None):\n",
    "    batch = val_iter.next()\n",
    "    img = batch.data[0].asnumpy()\n",
    "    img_ = img[0].transpose((1,2,0))\n",
    "    label_id = int(batch.label[0].asnumpy()[0])\n",
    "\n",
    "    encode_param=[int(cv2.IMWRITE_JPEG_QUALITY),90]\n",
    "    _,im=cv2.imencode('.jpg', img_, encode_param)\n",
    "    im = cv2.imdecode(im,1)\n",
    "    plt.imshow(im)\n",
    "    print(\"Ground truth [%d] - %s\\n\" %( label_id, object_classes[label_id] ) )\n",
    "    \n",
    "    # Convert the image to a Json array\n",
    "    data = json.dumps(img, cls=NumPyArangeEncoder)\n",
    "    #print(data)\n",
    "    if endpoint_name is None:\n",
    "        # Call our model for predicting\n",
    "        input_content_type = 'application/json'\n",
    "        output_content_type = 'application/json'\n",
    "        response = transform_fn(net, data, input_content_type, output_content_type)\n",
    "        \n",
    "    else:\n",
    "        sm = boto3.client('sagemaker-runtime')\n",
    "        response = sm.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=data\n",
    "        )\n",
    "        response = [response['Body'].read().decode('utf-8')]\n",
    "\n",
    "    for i in json.loads(response[0]):\n",
    "        label_id = int(list(i)[0])\n",
    "        print(\"Predicted [%d] - %s [%s]\" % (label_id, object_classes[label_id], i[str(label_id)] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our code locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.test_utils.download(dataset_dir + '/cars_all_test.lst', fname=\"cars_test.lst\", dirname=base_dir + '/data')\n",
    "mx.test_utils.download(dataset_dir + '/cars_all_train.lst', fname=\"cars_train.lst\", dirname=base_dir + '/data')\n",
    "mx.test_utils.download(dataset_dir + '/cars_all_test.rec', fname=\"cars_test.rec\", dirname=base_dir + '/data')\n",
    "mx.test_utils.download(dataset_dir + '/cars_all_train.rec', fname=\"cars_train.rec\", dirname=base_dir + '/data')\n",
    "!ls -lat $base_dir/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.test_utils.download(dataset_dir + '/dataset_classes.json', dirname=base_dir + '/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = json.loads(open(base_dir + '/data/dataset_classes.json', 'r').read())\n",
    "class_map = {}\n",
    "for l in classes['samples']:\n",
    "    class_map[l['id']] = l['name']\n",
    "\n",
    "object_classes = []\n",
    "for i,k in enumerate(sorted([\"%s\" % (i+1) for i in range(196)])):\n",
    "    object_classes.append(class_map[k] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our code locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some dummy variables for mocking sagemaker calls\n",
    "current_host='algo-1'\n",
    "hosts=['algo-1']\n",
    "list_cpus=!cat /proc/cpuinfo |grep processor|wc -l\n",
    "num_cpus=int(list_cpus[0])\n",
    "list_gpus=!nvidia-smi -L|wc -l\n",
    "num_gpus=int(list_gpus[0])\n",
    "print(\"GPUs: %d, CPUs: %d\" % (num_gpus, num_cpus))\n",
    "channel_input_dirs={\n",
    "    'training': base_dir + '/data'\n",
    "}\n",
    "hyperparameters = {\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 1,\n",
    "    \"log_interval\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create our final model (it takes around)\n",
    "!mkdir -p $model_dir\n",
    "!rm -f $model_dir/*\n",
    "# -> open the terminal and execute: watch nvidia-smi\n",
    "net = train(current_host, hosts, num_cpus, num_gpus, channel_input_dirs, model_dir, hyperparameters)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "save(net, model_dir)\n",
    "!ls -lat $model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive the model\n",
    "net = model_fn(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads a test dataset for testing\n",
    "val_iter = mx.image.ImageIter(\n",
    "    batch_size=1, data_shape=(3, 224, 224), \n",
    "    path_imglist=base_dir + '/data/cars_test.lst',\n",
    "    path_imgrec=base_dir + '/data/cars_test.rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's download an 88% accuracy model and overwrite our previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl $pre_trained_model | tar -xz -C $model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive the model again\n",
    "net = model_fn(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving all the functions into a python script.\n",
    "# It will be sent to a Sagemaker process\n",
    "code = open(base_dir + '/cars.py', 'w')\n",
    "code.write(\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "base_dir=\".\"\n",
    "\n",
    "\"\"\")\n",
    "for obj in [train, save, get_test_data, get_train_data, test, model_fn, transform_fn]:\n",
    "    code.write(inspect.getsource(obj) + '\\n')\n",
    "code.flush()\n",
    "code.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training your model on Sagemaker (you can skip this session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=base_dir + '/data/', key_prefix='data/cars')\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MXNet(base_dir + '/cars.py', \n",
    "          role=role, \n",
    "          train_instance_count=1, \n",
    "          train_instance_type=\"ml.p3.2xlarge\",\n",
    "          hyperparameters={'batch_size': 32, \n",
    "                           'epochs': 2,\n",
    "                           'learning_rate': 0.00007})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the 88% model to a Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl $pre_trained_model | tar -xz -C $model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_tarball = base_dir + '/model.tar.gz'\n",
    "entry_point = base_dir + '/cars.py'\n",
    "py_version='py3'\n",
    "endpoint_name='car-classification'\n",
    "model_name=endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tarball with the trained model\n",
    "tarball = tarfile.open(model_tarball, \"w:gz\" )\n",
    "for f in os.listdir(model_dir):\n",
    "    tarball.add(os.path.join(model_dir, f), arcname=f)\n",
    "tarball.close()\n",
    "\n",
    "!tar -tzvf $model_tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the tarball to an S3 Bucket\n",
    "model_data = sagemaker_session.upload_data(path=model_tarball, key_prefix='data/cars')\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Mxnet Estimator\n",
    "m = sagemaker.mxnet.model.MXNetModel(model_data=model_data, role=role, entry_point=entry_point, py_version=py_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Publishes the model. It takes around 8mins\n",
    "m.deploy(initial_instance_count=1, instance_type='ml.t2.medium', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter = mx.image.ImageIter(\n",
    "    batch_size=1, data_shape=(3, 224, 224), \n",
    "    path_imglist=base_dir + '/data/cars_test.lst',\n",
    "    path_imgrec=base_dir + '/data/cars_test.rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(val_iter, endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf $base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

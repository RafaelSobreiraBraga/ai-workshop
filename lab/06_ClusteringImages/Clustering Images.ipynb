{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering images for automatic classification\n",
    "\n",
    "A given company has lots of unclassified images stored in their servers. They want to use these images for creating a UI where their final customers would navigate through their products by selecting pictues. So, in this notebook we will use an unsupervised algorithm for clustering, called K-Means and then we will select sample from each cluster and send it to rekognition to extract the top-5 tags.\n",
    "\n",
    "- For each image in our dataset, we need to pass through the Visual Search CNN and get the image feature encoding vector\n",
    "- Then, we will train a K-Means model with the vectors\n",
    "- After that we will get a sample of each cluster and then call Rekognition for tagging each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir='/tmp/clustering'\n",
    "dataset_dir='https://spock.cloud/ai-workshop/furniture'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# Retrieve the default bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "!mkdir -p $base_dir\n",
    "if not os.path.exists(base_dir + '/furniture.raw.json'):\n",
    "    !curl $dataset_dir/furniture.raw.json -o $base_dir/furniture.raw.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_json(base_dir + '/furniture.raw.json')\n",
    "dataset[[ 'id', 'raw_hash', 'image_path']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset for the built-in K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = dataset['id'].values.tolist()\n",
    "hashes = dataset['raw_hash'].values.tolist()\n",
    "images = dataset['image_path'].values.tolist()\n",
    "\n",
    "train_set = np.array(hashes, dtype='float32')\n",
    "labels_set = np.array(labels)\n",
    "num_clusters = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the images for the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $base_dir/furniture\n",
    "!curl $dataset_dir/furniture.tar.gz | tar -xz -C $base_dir/furniture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans\n",
    "\n",
    "data_location = 's3://{}/clustering/data'.format(bucket)\n",
    "output_location = 's3://{}/clustering/output'.format(bucket)\n",
    "\n",
    "print('training data will be uploaded to: {}'.format(data_location))\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.c4.8xlarge',\n",
    "                output_path=output_location,\n",
    "                k=num_clusters,\n",
    "                data_location=data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kmeans.fit(kmeans.record_set(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint_name=kmeans_predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the endpont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = kmeans_predictor.predict(np.array([ train_set[0] ], dtype='float32') )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "import base64\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML, Javascript, display_javascript\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "sm = boto3.client('sagemaker-runtime') \n",
    "reko = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cluster(features):\n",
    "    result = sm.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps({\"instances\": [ {\"features\": features.tolist() } ] })\n",
    "    )\n",
    "    body = json.loads(result['Body'].read())\n",
    "    body = body['predictions'][0]\n",
    "    return int(body['closest_cluster']), body['distance_to_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_base64(filename):\n",
    "    image = Image.open( filename )\n",
    "    image = image.resize((224, 224))\n",
    "    image = image.convert(\"RGBA\")\n",
    "    newData = []\n",
    "    for item in image.getdata():\n",
    "        if item[0] >= 253 and item[1] >= 253 and item[2] >= 253:\n",
    "            newData.append((255, 255, 255, 0))\n",
    "        else:\n",
    "            newData.append(item)\n",
    "\n",
    "    image.putdata(newData)\n",
    "    \n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('ascii')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cluster(cluster_id=None):\n",
    "    ids_images = []\n",
    "    clusters = []\n",
    "    furniture_links = \"\"\n",
    "    if cluster_id is None:\n",
    "        clusters = random.sample(range(0,num_clusters), 6)\n",
    "        ids_images = [images_inside_clusters[i][0] for i in clusters]   \n",
    "    else:\n",
    "        max_elements = min(len(images_inside_clusters[cluster_id]), 10)\n",
    "        clusters = [cluster_id for i in range(max_elements)]\n",
    "        random.shuffle(images_inside_clusters[cluster_id])\n",
    "        ids_images = [i for i in images_inside_clusters[cluster_id][0:max_elements]]\n",
    "        furniture_links = '<li><a onclick=\"loadCluster()\" href=\"#\"><img width=\"10%\" height=\"10%\" src=\"https://spock.cloud/ai-workshop/misc/images/return.png\"></img>RETURN</a></li>'\n",
    "    \n",
    "    for c,i in zip(clusters, ids_images):\n",
    "        furniture_links += '<li><a onclick=\"loadCluster({0})\" href=\"#\">'.format(c)\n",
    "        furniture_links += '<img width=\"30%\" height=\"30%\" src=\"data:image/png;base64,{0}\"></img>'.format(get_image_base64(os.path.join( base_dir, 'furniture', images[i[0]] ) ) )\n",
    "        furniture_links += 'C. {0} - {1} imgs. - dist. {2:.2f} - tags. {3}</a></li>'.format(c,len(images_inside_clusters[c]), i[1], \" \".join(tags[c]))\n",
    "\n",
    "    return furniture_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reads an image from the disk and coverts it to a bytearray\n",
    "def load_image(filename):\n",
    "    with open(filename, \"rb\") as imageFile:\n",
    "        f = imageFile.read()\n",
    "        return bytearray(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's classify all the images and see in which clusters they belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "images_inside_clusters = {}\n",
    "for img_id,i in enumerate(train_set):\n",
    "    cluster_id, distance = get_cluster(i)\n",
    "    \n",
    "    if images_inside_clusters.get(cluster_id) is None:\n",
    "        images_inside_clusters[cluster_id] = []\n",
    "    images_inside_clusters[cluster_id].append( [img_id, distance ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(columns=['cluster_id', 'image_id', 'image_dist'])\n",
    "for i in range(len(images_inside_clusters)):\n",
    "    for j in images_inside_clusters[i]:\n",
    "        stats = stats.append({\n",
    "            'cluster_id': i, \n",
    "            'image_id': j[0], \n",
    "            'image_dist': j[1]\n",
    "        }, ignore_index=True)\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.drop('image_id', axis=1).groupby('cluster_id').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the labels from Rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {}\n",
    "for i,k in enumerate(stats.groupby('cluster_id').min().values):\n",
    "    tags[i] = []\n",
    "    filename = dataset[(dataset.id == k[0])]['image_path'].values[0]\n",
    "    response = reko.detect_labels(\n",
    "        Image={'Bytes': load_image(os.path.join( base_dir, 'furniture', filename) )},\n",
    "        MaxLabels=5,\n",
    "        MinConfidence=75\n",
    "    )\n",
    "    for k in response['Labels']:\n",
    "        tags[i].append(k['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, render the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''\n",
    "<script type=\"text/javascript\" src=\"https://spock.cloud/ai-workshop/misc/js/tagcanvas.min.js\"></script>\n",
    "\n",
    "<div id=\"myCanvasContainer\">\n",
    " <canvas width=\"600\" height=\"600\" id=\"myCanvas\">\n",
    "  <p>Anything in here will be replaced on browsers that support the canvas element</p>\n",
    "  <ul id='tags'></ul>\n",
    " </canvas>\n",
    "</div>\n",
    "\n",
    "<script type=\"text/javascript\">\n",
    "\n",
    "    function handle_output(out) {\n",
    "        if ( !out.content || !out.content.data || !out.content.data[\"text/plain\"] ) {\n",
    "            console.log( out )\n",
    "            return;\n",
    "        } // if\n",
    "        \n",
    "        document.getElementById('tags').innerHTML = out.content.data[\"text/plain\"];\n",
    "        \n",
    "        TagCanvas.Start('myCanvas', 'myCanvasContainer', {\n",
    "            textColour: '#000000',\n",
    "            outlineColour: '#ff00ff',\n",
    "            reverse: true,\n",
    "            depth: 0.8,\n",
    "            maxSpeed: 0.05,\n",
    "            imageMode: 'both',\n",
    "            imagePosition: 'bottom',\n",
    "            wheelZoom: false\n",
    "        });\n",
    "\n",
    "    }\n",
    "\n",
    "    function loadCluster(id) {\n",
    "        console.log(\"ClusterID: \" + id)\n",
    "        id = id == undefined ? \"\":id;\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        \n",
    "        var callbacks = { 'iopub' : {'output' : handle_output}};\n",
    "        \n",
    "        resp = kernel.execute(\"load_cluster(\" + id + \")\", callbacks, {silent:false});\n",
    "    }\n",
    "</script>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jso = Javascript(\"loadCluster();\")\n",
    "display_javascript(jso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker.Session().delete_endpoint(kmeans_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

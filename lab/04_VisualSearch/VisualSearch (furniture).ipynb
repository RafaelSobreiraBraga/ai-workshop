{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global vars/imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir='/tmp/visual'\n",
    "model_dir=base_dir + '/model'\n",
    "dataset_dir='https://spock.cloud/ai-workshop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernel conda_mxnet_p36\n",
    "\n",
    "%matplotlib inline\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import sagemaker\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import inspect\n",
    "import random\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "from PIL import Image\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MxNet container functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(current_host, hosts, num_cpus, num_gpus, channel_input_dirs, model_dir, hyperparameters, **kwargs):\n",
    "    ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "    mx.random.seed(127)\n",
    "    \n",
    "    path='http://data.mxnet.io/models/imagenet-11k/'\n",
    "    [mx.test_utils.download(path+'resnet-152/resnet-152-symbol.json', dirname=base_dir),\n",
    "     mx.test_utils.download(path+'resnet-152/resnet-152-0000.params', dirname=base_dir),\n",
    "     mx.test_utils.download(path+'synset.txt', dirname=base_dir)]\n",
    "    \n",
    "    sym, arg_params, aux_params = mx.model.load_checkpoint(base_dir + '/resnet-152', 0)\n",
    "    \n",
    "    mod = mx.mod.Module(symbol=sym, context=ctx, label_names=None)\n",
    "    mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "        label_shapes=mod._label_shapes)\n",
    "    mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "    \n",
    "    all_layers = sym.get_internals()\n",
    "\n",
    "    hash_output = all_layers['flatten0_output']\n",
    "    hash_output = mx.symbol.LogisticRegressionOutput(data=hash_output, name='sig')\n",
    "\n",
    "    net = mx.symbol.Group([hash_output, all_layers[\"softmax_output\"]])\n",
    "\n",
    "    image_search_mod = mx.mod.Module(symbol=net, context=ctx, label_names=[ 'sig_label', 'softmax_label'])\n",
    "    image_search_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "        label_shapes=image_search_mod._label_shapes)\n",
    "    image_search_mod.set_params(arg_params, aux_params, allow_missing=False)\n",
    "    \n",
    "    return image_search_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(net, model_dir):\n",
    "    net.save_checkpoint('%s/model' % model_dir, 0)\n",
    "    \n",
    "    shapes = open ( '%s/model-shapes.json' % model_dir, \"w\")\n",
    "    json.dump([{\"shape\": net.data_shapes[0][1], \"name\": \"data\"}], shapes)\n",
    "    shapes.flush()\n",
    "    shapes.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data(data_dir, batch_size, data_shape):\n",
    "    return None\n",
    "\n",
    "def get_train_data(data_dir, batch_size, data_shape):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(ctx, net, test_data):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the model. Called once when hosting service starts.\n",
    "\n",
    "    :param: model_dir The directory where model files are stored.\n",
    "    :return: a model (in this case a network)\n",
    "    \"\"\"\n",
    "    net, arg_params, aux_params = mx.model.load_checkpoint(os.path.join(model_dir, 'model'), 0)\n",
    "\n",
    "    image_search_mod = mx.mod.Module(symbol=net, context=mx.cpu(), label_names=[ 'sig_label', 'softmax_label'])\n",
    "    image_search_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "        label_shapes=image_search_mod._label_shapes)\n",
    "    image_search_mod.set_params(arg_params, aux_params, allow_missing=False)\n",
    "\n",
    "    return image_search_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fn(net, data, input_content_type, output_content_type):\n",
    "    \"\"\"\n",
    "    Transform a request using the model. Called once per request.\n",
    "\n",
    "    :param net: The model.\n",
    "    :param data: The request payload.\n",
    "    :param input_content_type: The request content type.\n",
    "    :param output_content_type: The (desired) response content type.\n",
    "    :return: response payload and content type.\n",
    "    \"\"\"\n",
    "    resp = []\n",
    "\n",
    "    try:\n",
    "        Batch = namedtuple('Batch', ['data'])\n",
    "        \n",
    "        parsed = json.loads(data)\n",
    "        img = mx.nd.array([parsed])\n",
    "        \n",
    "        net.forward(Batch([img]))\n",
    "        raw_features = net.get_outputs()[0][0].asnumpy()\n",
    "\n",
    "        prob_cat = net.get_outputs()[1][0].asnumpy()\n",
    "        prob_cat = np.squeeze(prob_cat)\n",
    "        index_cat = np.argsort(prob_cat)[::-1]\n",
    "        categories = []\n",
    "        for i in index_cat[0:10]:\n",
    "            categories.append( [int(i), float(prob_cat[i]) ] )\n",
    "\n",
    "        hash_ =  \"\".join( map(str, np.where(raw_features >= 0.75, 1, 0) ) )\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "\n",
    "    return json.dumps({\"categories\": categories, \"hash\": hash_, \"raw_features\": raw_features }), output_content_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and prepare an image\n",
    "def get_image(img_name):\n",
    "    img = Image.open(img_name)\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder for converting numpy to json\n",
    "class NumPyArangeEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist() # or map(int, obj)\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the Hamming distance between two bit strings\n",
    "def hamming2(s1, s2):\n",
    "    assert len(s1) == len(s2)\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the sagemaker endpoint for VisualSearch and return the response\n",
    "def get_visual_data(img, endpoint_name):\n",
    "    sm = boto3.client('sagemaker-runtime')\n",
    "    response = sm.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(img, cls=NumPyArangeEncoder)\n",
    "    )\n",
    "    response = json_deserializer(response['Body'], response['ContentType'])  \n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search in the metadata list the most similar objects\n",
    "def search_local_base(metadata, endpoint_name, file_name=None):\n",
    "    try: \n",
    "        image = get_image(file_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    item_hash = get_visual_data(image, endpoint_name)\n",
    "    \n",
    "    # get the item categories\n",
    "    categories = list(map( lambda x: ( object_classes[x[0]], x[1]), item_hash['categories']))\n",
    "    \n",
    "    # measure the distance to each item\n",
    "    dist = {}\n",
    "    for meta in metadata:\n",
    "        dist[meta['id']] = hamming2( item_hash['hash'], meta['hash'] )\n",
    "    \n",
    "    result = []\n",
    "    for w in sorted(dist, key=dist.get, reverse=False):\n",
    "        result.append( (dist[w], metadata[w][ 'image_path']) )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Render the top five items\n",
    "def render_top_five(result):\n",
    "    f, axarr = plt.subplots(1, 5, figsize=(20,12))\n",
    "    for i in range(5):\n",
    "        im = Image.open(base_dir + '/furniture/%s' % result[5:10][i][1])\n",
    "        frame = axarr[i].imshow(im)   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $model_dir\n",
    "# Saving all the functions into a python script.\n",
    "# It will be sent to a Sagemaker process\n",
    "code = open(base_dir + '/visual.py', 'w')\n",
    "code.write(\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "\"\"\")\n",
    "for func in [train, save, get_test_data, get_train_data, test, model_fn, transform_fn]:\n",
    "    code.write(inspect.getsource(func) + '\\n')\n",
    "code.flush()\n",
    "code.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the hacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some dummy variables for mocking sagemaker calls\n",
    "current_host='algo-1'\n",
    "hosts=['algo-1']\n",
    "list_cpus=!cat /proc/cpuinfo |grep processor|wc -l\n",
    "num_cpus=int(list_cpus[0])\n",
    "\n",
    "num_gpus=0\n",
    "print(\"GPUs: %d, CPUs: %d\" % (num_gpus, num_cpus))\n",
    "channel_input_dirs={\n",
    "    'training': '/opt/ml/input/data/training'\n",
    "}\n",
    "hyperparameters = {\n",
    "    \"learning_rate\": 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create our final model\n",
    "net = train(current_host, hosts, num_cpus, num_gpus, channel_input_dirs, model_dir, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "save(net, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (you can skip this session) Testing our code locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrive the model\n",
    "net = model_fn(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download a test image\n",
    "mx.test_utils.download(dataset_dir + '/furniture/chair.jpg', dirname=base_dir)\n",
    "img = get_image(base_dir + '/chair.jpg')\n",
    "\n",
    "# Convert the image to a Json array\n",
    "data = json.dumps(img, cls=NumPyArangeEncoder)\n",
    "\n",
    "# Call our model for predicting\n",
    "input_content_type = 'application/json'\n",
    "output_content_type = 'application/json'\n",
    "response = transform_fn(net, data, input_content_type, output_content_type)\n",
    "\n",
    "# Print the computed hash\n",
    "resp = json.loads(response[0])\n",
    "print( \"Hash [%s]\" % resp['hash'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model to a Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='http://data.mxnet.io/models/imagenet-11k/'\n",
    "[mx.test_utils.download(path+'resnet-152/resnet-152-symbol.json', dirname=model_dir),\n",
    "     mx.test_utils.download(path+'resnet-152/resnet-152-0000.params', dirname=model_dir),\n",
    "     mx.test_utils.download(path+'synset.txt', dirname=model_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_tarball = base_dir + '/model.tar.gz'\n",
    "entry_point = base_dir + '/visual.py'\n",
    "py_version='py3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the current Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a tarball with the trained model\n",
    "tarball = tarfile.open(model_tarball, \"w:gz\" )\n",
    "for f in os.listdir(model_dir):\n",
    "    tarball.add(os.path.join(model_dir, f), arcname=f)\n",
    "tarball.close()\n",
    "\n",
    "!tar -tzvf $model_tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upload the tarball to an S3 Bucket\n",
    "model_data = sagemaker_session.upload_data(path=model_tarball, key_prefix='data/visual')\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an Mxnet Estimator\n",
    "m = sagemaker.mxnet.model.MXNetModel(model_data=model_data, role=role, entry_point=entry_point, py_version=py_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Publishes the model. It takes around 8mins\n",
    "predictor = m.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the ImageNet categories\n",
    "synset = open(base_dir + '/synset.txt', 'r')\n",
    "object_classes = []\n",
    "for l in synset:\n",
    "    object_classes.append(l.split(' ')[1].replace('\\n', ''))\n",
    "synset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's download a furniture dataset for our tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $base_dir/furniture\n",
    "!curl $dataset_dir/furniture.tar.gz | tar -xz -C $base_dir/furniture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the dataset metadata\n",
    "mx.test_utils.download(dataset_dir + '/furniture/furniture.json', dirname=base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download a test image\n",
    "mx.test_utils.download(dataset_dir + '/furniture/nightstand.jpg', dirname=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching with a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loads the dataset metadata\n",
    "metadata = json.loads(open(base_dir + '/furniture.json', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(Image.open(base_dir + '/nightstand.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Runs a search, based on the test image\n",
    "result = search_local_base(metadata, endpoint_name, base_dir + '/nightstand.jpg')\n",
    "render_top_five(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "file_names = list(metadata)\n",
    "random.shuffle(file_names)\n",
    "file_name = base_dir + '/furniture/%s' % file_names[0]['image_path']\n",
    "plt.imshow(Image.open(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = search_local_base(metadata, endpoint_name, file_name )\n",
    "render_top_five(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf $base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
